{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc1a677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINER\n",
    "from imageai.Detection.Custom import DetectionModelTrainer\n",
    "\n",
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "\n",
    "trainer.setDataDirectory(data_directory=\"MY_DATASET\")\n",
    "trainer.setTrainConfig(object_names_array=[\"Bottle\"], batch_size=2, num_experiments=10)\n",
    "# In the above,when training for detecting multiple objects,\n",
    "#set object_names_array=[\"object1\", \"object2\", \"object3\",...\"objectz\"]\n",
    "trainer.trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4e0fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TINY\n",
    "from imageai.Detection import ObjectDetection\n",
    "\n",
    "detector = ObjectDetection()\n",
    "\n",
    "detector.setModelTypeAsTinyYOLOv3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251f6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sur une vidéo\n",
    "\n",
    "from imageai.Detection.Custom import CustomVideoObjectDetection\n",
    "import os\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "video_detector = CustomVideoObjectDetection()\n",
    "video_detector.setModelTypeAsYOLOv3()\n",
    "video_detector.setModelPath(\"\\MY_DATASET\\models\\detection_model-ex-022--loss-0025.143.h5\")\n",
    "video_detector.setJsonPath(\"\\MY_DATASET\\json\\detection_config.json\")\n",
    "video_detector.loadModel()\n",
    "\n",
    "video_detector.detectObjectsFromVideo(input_file_path=\"holo1.mp4\",\n",
    "                                          output_file_path=os.path.join(execution_path, \"holo1-detected3\"),\n",
    "                                          frames_per_second=20,\n",
    "                                          minimum_percentage_probability=40,\n",
    "                                          log_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fd0afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capture une vidéo\n",
    "from imageai.Detection.Custom import CustomVideoObjectDetection\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "video_detector = CustomVideoObjectDetection()\n",
    "video_detector.setModelTypeAsYOLOv3()\n",
    "video_detector.setModelPath(\"MY_DATASET\\models\\detection_model-ex-022--loss-0025.143.h5\")\n",
    "video_detector.setJsonPath(\"MY_DATASET\\json\\detection_config.json\")\n",
    "video_detector.loadModel(detection_speed=\"fast\")\n",
    "\n",
    "video_detector.detectObjectsFromVideo(camera_input=camera,\n",
    "                                          output_file_path=os.path.join(execution_path, \"holo1-detected3\"),\n",
    "                                          frames_per_second=1,\n",
    "                                          minimum_percentage_probability=10,\n",
    "                                          log_progress=True)\n",
    "\n",
    "k=cv2.waitKey(1)\n",
    "if k == ord('q'):\n",
    "    camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4098d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a132241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forFrame(frame_number, output_array, output_count):\n",
    "    print(\"FOR FRAME \" , frame_number)\n",
    "    print(\"Output for each object : \", output_array)\n",
    "    print(\"Output count for unique objects : \", output_count)\n",
    "    print(\"------------END OF A FRAME --------------\")\n",
    "\n",
    "def forSeconds(second_number, output_arrays, count_arrays, average_output_count):\n",
    "    print(\"SECOND : \", second_number)\n",
    "    print(\"Array for the outputs of each frame \", output_arrays)\n",
    "    print(\"Array for output count for unique objects in each frame : \", count_arrays)\n",
    "    print(\"Output average count for unique objects in the last second: \", average_output_count)\n",
    "    print(\"------------END OF A SECOND --------------\")\n",
    "\n",
    "def forMinute(minute_number, output_arrays, count_arrays, average_output_count):\n",
    "    print(\"MINUTE : \", minute_number)\n",
    "    print(\"Array for the outputs of each frame \", output_arrays)\n",
    "    print(\"Array for output count for unique objects in each frame : \", count_arrays)\n",
    "    print(\"Output average count for unique objects in the last minute: \", average_output_count)\n",
    "    print(\"------------END OF A MINUTE --------------\")\n",
    "\n",
    "video_detector = CustomVideoObjectDetection()\n",
    "video_detector.setModelTypeAsYOLOv3()\n",
    "video_detector.setModelPath(\"hololens-ex-60--loss-2.76.h5\")\n",
    "video_detector.setJsonPath(\"detection_config.json\")\n",
    "video_detector.loadModel()\n",
    "\n",
    "video_detector.detectObjectsFromVideo(camera_input=camera,\n",
    "                                          output_file_path=os.path.join(execution_path, \"holo1-detected3\"),\n",
    "                                          frames_per_second=20, per_second_function=forSeconds, per_frame_function = forFrame, per_minute_function= forMinute,\n",
    "                                          minimum_percentage_probability=40,\n",
    "                                          log_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1e5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Detection.Custom import CustomVideoObjectDetection\n",
    "import os\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "video_detector = CustomVideoObjectDetection()\n",
    "video_detector.setModelTypeAsYOLOv3()\n",
    "video_detector.setModelPath(\"MY_DATASET\\models\\detection_model-ex-022--loss-0025.143.h5\")\n",
    "video_detector.setJsonPath(\"MY_DATASET\\json\\detection_config.json\")\n",
    "video_detector.loadModel()\n",
    "\n",
    "video_detector.detectObjectsFromVideo(input_file_path=\"MES_BOUTEILLES\\WIN_20220305_17_40_36_Pro.mp4\",\n",
    "                                          output_file_path=os.path.join(execution_path, \"holo1-detected3\"),\n",
    "                                          frames_per_second=20,\n",
    "                                          minimum_percentage_probability=20,\n",
    "                                          log_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c40f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Capture une vidéo\n",
    "from imageai.Detection import ObjectDetection\n",
    "from imageai.Detection.Custom import CustomVideoObjectDetection\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "video_detector = CustomVideoObjectDetection()\n",
    "video_detector.setModelTypeAsTinyYOLOv3()\n",
    "video_detector.setModelPath(\"MY_DATASETv2\\models\\detection_model-ex-022--loss-0025.143.h5\")\n",
    "video_detector.setJsonPath(\"MY_DATASETv2\\json\\detection_config.json\")\n",
    "video_detector.loadModel(detection_speed=\"fast\")\n",
    "\n",
    "video_detector.detectObjectsFromVideo(camera_input=camera,\n",
    "                                          output_file_path=os.path.join(execution_path, \"holo1-detected3\"),\n",
    "                                          frames_per_second=1,\n",
    "                                          minimum_percentage_probability=10,\n",
    "                                          log_progress=True)\n",
    "\n",
    "k=cv2.waitKey(1)\n",
    "if k == ord('q'):\n",
    "    camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    " \n",
    "camera = cv2.VideoCapture(1)\n",
    "while True:\n",
    "    return_value, image = camera.read()\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('image',image)\n",
    "    \n",
    "    k=cv2.waitKey(1)\n",
    "    if k == ord('q'): \n",
    "        camera.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af0591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train for images\n",
    "from imageai.Detection import ObjectDetection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22579d11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Setting parallel_iterations > 1 has no effect when executing eagerly. Consider calling map_fn with tf.function to execute fn in parallel.\n"
     ]
    }
   ],
   "source": [
    "#RETINANET\n",
    "#https://www.youtube.com/watch?v=bUoWTPaKUi4\n",
    "#Press q to shut down the program\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "from imageai.Detection.Custom import CustomVideoObjectDetection\n",
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "\n",
    "##Neural network\n",
    "#net = cv2.dnn.readNet(model=\"dnn_model\\yolov4-tiny.weights\", config=\"dnn_model\\yolov4-tiny.cfg\")\n",
    "#model = cv2.dnn_DetectionModel(net)\n",
    "##Resize into a small square (320,320) to process a fast analysis\n",
    "##Scale because the dnn go from 0 to 1 and the pixel value from 0 to 255\n",
    "#model.setInputParams(size=(320,320), scale=1/255)\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "video_detector = ObjectDetection()\n",
    "video_detector.setModelTypeAsRetinaNet()\n",
    "video_detector.setModelPath(\"resnet50_coco_best_v2.1.0.h5\")\n",
    "#video_detector.setJsonPath(\"MY_DATASET\\json\\detection_config.json\")\n",
    "video_detector.loadModel()\n",
    "custom_objects = video_detector.CustomObjects(bottle=True)\n",
    "\n",
    "classes = []\n",
    "with open(\"LIVE\\classes.txt\", \"r\") as file_object:\n",
    "    for class_name in file_object.readlines():\n",
    "        #To get the good shape of inputs\n",
    "        class_name = class_name.strip()\n",
    "        classes.append(class_name)\n",
    "\n",
    "#Camera initialization\n",
    "cap = cv2.VideoCapture(0)\n",
    "#Increase camera resolution (Care on rasp)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "#HD 1920 x 1080\n",
    "\n",
    "while True:\n",
    "    #Receive the frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    #Object detection\n",
    "    #(class_ids, score, bound_boxes) = model.detect(frame)\n",
    "    \n",
    "    #for class_ids, score, bound_boxes in zip(class_ids, score, bound_boxes):\n",
    "    #    x, y, w, h = bound_boxes\n",
    "    #    #print(x, y, h, w)\n",
    "    #    class_name=classes[int(class_ids)]\n",
    "    #    \n",
    "    #    if class_name==\"bottle\":\n",
    "    #    \n",
    "    #        cv2.putText(frame, str(class_name), (x, y - 5), cv2.FONT_HERSHEY_PLAIN, 3, (200, 0, 50), 2)\n",
    "    #        cv2.rectangle(frame, (x,y), (x+w,y+h), (200, 0, 50), 3)\n",
    "    #print(\"class\", class_ids)\n",
    "    #print(\"scores\", score)\n",
    "    #print(\"boxes\", bound_boxes)\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('q'):\n",
    "        cap.release()\n",
    "        cv2. destroyAllWindows()\n",
    "        break\n",
    "        \n",
    "    if k == ord('s'):\n",
    "        cv2.imwrite(\"pic.png\", frame)\n",
    "        bottle_det = video_detector.detectObjectsFromImage(custom_objects=custom_objects, input_image=os.path.join(execution_path , \"pic.png\"), output_image_path=os.path.join(execution_path, \n",
    "                                                    \"det.png\"), minimum_percentage_probability=30, \n",
    "                                                     display_percentage_probability=True, display_object_name=True)\n",
    "        pic_det = cv2.imread('det.png')\n",
    "        cv2.imshow('test', pic_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d071d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TINYYOLO\n",
    "#https://www.youtube.com/watch?v=bUoWTPaKUi4\n",
    "#Press q to shut down the program\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "from imageai.Detection.Custom import CustomVideoObjectDetection\n",
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "##Neural network\n",
    "#net = cv2.dnn.readNet(model=\"dnn_model\\yolov4-tiny.weights\", config=\"dnn_model\\yolov4-tiny.cfg\")\n",
    "#model = cv2.dnn_DetectionModel(net)\n",
    "##Resize into a small square (320,320) to process a fast analysis\n",
    "##Scale because the dnn go from 0 to 1 and the pixel value from 0 to 255\n",
    "#model.setInputParams(size=(320,320), scale=1/255)\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "video_detector = ObjectDetection()\n",
    "video_detector.setModelTypeAsTinyYOLOv3()\n",
    "video_detector.setModelPath(\"yolo-tiny.h5\")\n",
    "#video_detector.setJsonPath(\"MY_DATASETv2\\json\\detection_config.json\")\n",
    "video_detector.loadModel(\"flash\")\n",
    "custom_objects = video_detector.CustomObjects(bottle=True)\n",
    "\n",
    "classes = []\n",
    "with open(\"LIVE\\classes.txt\", \"r\") as file_object:\n",
    "    for class_name in file_object.readlines():\n",
    "        #To get the good shape of inputs\n",
    "        class_name = class_name.strip()\n",
    "        classes.append(class_name)\n",
    "\n",
    "#Camera initialization\n",
    "cap = cv2.VideoCapture(0)\n",
    "#Increase camera resolution (Care on rasp)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "#HD 1920 x 1080\n",
    "\n",
    "while True:\n",
    "    #Receive the frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    #Object detection\n",
    "    #(class_ids, score, bound_boxes) = model.detect(frame)\n",
    "    \n",
    "    #for class_ids, score, bound_boxes in zip(class_ids, score, bound_boxes):\n",
    "    #    x, y, w, h = bound_boxes\n",
    "    #    #print(x, y, h, w)\n",
    "    #    class_name=classes[int(class_ids)]\n",
    "    #    \n",
    "    #    if class_name==\"bottle\":\n",
    "    #    \n",
    "    #        cv2.putText(frame, str(class_name), (x, y - 5), cv2.FONT_HERSHEY_PLAIN, 3, (200, 0, 50), 2)\n",
    "    #        cv2.rectangle(frame, (x,y), (x+w,y+h), (200, 0, 50), 3)\n",
    "    #print(\"class\", class_ids)\n",
    "    #print(\"scores\", score)\n",
    "    #print(\"boxes\", bound_boxes)\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('q'):\n",
    "        cap.release()\n",
    "        cv2. destroyAllWindows()\n",
    "        break\n",
    "        \n",
    "    if k == ord('s'):\n",
    "        cv2.imwrite(\"pic.png\", frame)\n",
    "        bottle_det = video_detector.detectObjectsFromImage(custom_objects=custom_objects, input_image=os.path.join(execution_path , \"pic.png\"), output_image_path=os.path.join(execution_path, \n",
    "                                                    \"det.png\"), minimum_percentage_probability=30, \n",
    "                                                     display_percentage_probability=True, display_object_name=True)\n",
    "        pic_det = cv2.imread('det.png')\n",
    "        cv2.imshow('test', pic_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b522f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINER\n",
    "from imageai.Detection.Custom import DetectionModelTrainer\n",
    "\n",
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "\n",
    "trainer.setDataDirectory(data_directory=\"MY_DATASETv2\")\n",
    "trainer.setTrainConfig(object_names_array=[\"Bottle\"], batch_size=2, num_experiments=1, train_from_pretrained_model=\"yolo-tiny.h5\")\n",
    "# In the above,when training for detecting multiple objects,\n",
    "#set object_names_array=[\"object1\", \"object2\", \"object3\",...\"objectz\"]\n",
    "trainer.trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d87a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\space\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    }
   ],
   "source": [
    "#YOLO\n",
    "#Our DATASET\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "from imageai.Detection.Custom import CustomVideoObjectDetection\n",
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "from imageai.Detection.Custom import CustomObjectDetection\n",
    "\n",
    "detector = CustomObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(\"MY_DATASET\\models\\detection_model-ex-022--loss-0025.143.h5\")\n",
    "detector.setJsonPath(\"MY_DATASET\\json\\detection_config.json\")\n",
    "detector.loadModel()\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "#custom_objects = detector.CustomObjects(bottle=True)\n",
    "\n",
    "classes = []\n",
    "with open(\"LIVE\\classes.txt\", \"r\") as file_object:\n",
    "    for class_name in file_object.readlines():\n",
    "        #To get the good shape of inputs\n",
    "        class_name = class_name.strip()\n",
    "        classes.append(class_name)\n",
    "\n",
    "#Camera initialization\n",
    "cap = cv2.VideoCapture(0)\n",
    "#Increase camera resolution (Care on rasp)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "#HD 1920 x 1080\n",
    "\n",
    "while True:\n",
    "    #Receive the frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('q'):\n",
    "        cap.release()\n",
    "        cv2. destroyAllWindows()\n",
    "        break\n",
    "        \n",
    "    if k == ord('s'):\n",
    "        cv2.imwrite(\"pic.png\", frame)\n",
    "        bottle_det = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"pic.png\"), output_image_path=os.path.join(execution_path, \n",
    "                                                    \"det.png\"), minimum_percentage_probability=10, \n",
    "                                                     display_percentage_probability=True, display_object_name=True)\n",
    "        pic_det = cv2.imread('det.png')\n",
    "        cv2.imshow('test', pic_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a884f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef0f27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
